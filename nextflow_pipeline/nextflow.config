/*
========================================================================================
    FIBER-SEQ PIPELINE CONFIGURATION
========================================================================================
*/

// Load base.config by default
includeConfig 'conf/base.config'

// Load modules.config
includeConfig 'modules.config'

/*
========================================================================================
    PARAMETERS
========================================================================================
*/

params {
    // -------------------------
    // Input/Output
    // -------------------------
    input                     = null          // Samplesheet TSV (required)
    outdir                    = null          // Output directory (required)

    // -------------------------
    // Reference Genome
    // -------------------------
    fasta                     = null          // Reference FASTA (required)
    fasta_index               = null          // Optional pre-built MMI index
    chrom_sizes               = null          // Chromosome sizes file (required for bigWig)

    // -------------------------
    // Alignment (Step 1)
    // -------------------------
    skip_alignment            = false         // Skip alignment (input BAMs are pre-aligned)
    pbmm2_preset              = 'HIFI'        // SUBREAD, CCS, HIFI, ISOSEQ

    // -------------------------
    // Nucleosome Calling (Step 2)
    // -------------------------
    ft_nucleosome_options     = ''            // Additional options for ft add-nucleosomes

    // -------------------------
    // QC Steps
    // -------------------------
    run_sequencing_qc         = false         // Run PacBio sequencing QC (requires SMRT Tools)
    run_fiberseq_qc           = false         // Run fiberseq-qc suite (requires tcsh + custom tools)

    // -------------------------
    // Pileup (Step 4)
    // -------------------------
    pileup_region             = null          // Optional region (chr:start-end)
    ml_threshold              = null          // ML threshold for ft pileup
    ft_pileup_options         = ''            // Additional options for ft pileup

    // -------------------------
    // BigWig Generation (Step 5)
    // -------------------------
    marks                     = 'm6a,nuc,cpg' // Comma-separated marks to generate

    // -------------------------
    // Heatmaps (Step 6)
    // -------------------------
    regions_bed               = null          // BED file for heatmaps
    matrix_mode               = 'reference-point'  // or 'scale-regions'
    reference_point           = 'center'      // center, TSS, TES
    upstream                  = 2000
    downstream                = 2000
    region_body_length        = 5000          // For scale-regions mode
    scale_upstream            = 3000          // Upstream for scale-regions mode
    scale_downstream          = 3000          // Downstream for scale-regions mode
    heatmap_height            = 15
    heatmap_width             = 4
    heatmap_colormap_m6a      = 'Greens'      // Colormap for m6A heatmaps
    heatmap_colormap_nuc      = 'Blues'       // Colormap for nucleosome heatmaps
    heatmap_colormap_cpg      = 'Reds'        // Colormap for CpG heatmaps

    // -------------------------
    // Part 2: Chromosome Filtering (Step 7)
    // -------------------------
    filter_chromosomes        = null          // Space-separated list: 'chr1 chr2 chr3'

    // -------------------------
    // Part 2: k-mer Phasing (Step 8)
    // -------------------------
    run_kmer_phasing          = false
    kmer_use_filtered         = false         // Use filtered BAM from step 7
    kmer_align                = false         // Perform alignment in k-mer phasing
    resume_kmer_phasing       = false         // Add --rerun-incomplete flag
    kmer_parental_mode        = false         // Enable parental data for phasing
    kmer_maternal_bam         = null          // Path to maternal sequencing data
    kmer_paternal_bam         = null          // Path to paternal sequencing data

    // -------------------------
    // Part 2: FIRE Peak Calling (Step 9)
    // -------------------------
    run_fire                  = false
    fire_input_source         = 'nucleosomes' // Input: 'nucleosomes' (step 2) or 'kmer_phasing' (step 8)
    fire_ref_name             = 'hg38'        // UCSC genome name for track hub
    fire_ont                  = false         // ONT Fiber-seq mode (vs PacBio)
    fire_max_threads          = null          // Max threads for distributed steps
    fire_keep_chromosomes     = null          // Regex filter (e.g., 'chr[0-9XY]+$')
    fire_excludes             = null          // BED files to exclude from null distribution
    fire_min_contig_length    = 0             // Skip contigs smaller than this
    fire_max_peak_fdr         = null          // FDR for FIRE peaks (default: 0.05)
    fire_min_fire_fdr         = null          // FDR for individual elements (default: 0.10)
    fire_min_coverage         = null          // Min coverage for peaks (default: 4)
    fire_coverage_within_n_sd = null          // Filter peaks beyond N SDs (default: 5)
    fire_min_msp              = null          // Min MSPs per read (default: 10)
    fire_min_ave_msp_size     = null          // Min average MSP size (default: 10)
    fire_min_per_acc_peak     = null          // Min fraction actuated (default: 0.0)
    fire_min_frac_accessible  = null          // Additional % actuation filter (default: 0.0)

    // -------------------------
    // Snakemake Workflows (for Part 2)
    // -------------------------
    kmer_pixi_manifest        = null          // pixi.toml for k-mer phasing (k-mer-variant-phasing repo)
    kmer_snakemake_profile    = null          // Snakemake profile for k-mer phasing
    fire_pixi_manifest        = null          // pixi.toml for FIRE (FIRE repo)
    fire_snakemake_profile    = null          // Snakemake profile for FIRE

    // -------------------------
    // External Tool Paths (for HPC without containers)
    // -------------------------
    smrt_root                 = null          // SMRT Tools installation path
    smrt_container            = null          // SMRT Tools Singularity container
    fiberseq_qc_root          = null          // fiberseq-qc installation path
    fiberseq_qc_container     = null          // fiberseq-qc Singularity container

    // -------------------------
    // Generic Options
    // -------------------------
    help                      = false
    publish_dir_mode          = 'copy'
    max_memory                = '128.GB'
    max_cpus                  = 16
    max_time                  = '72.h'
}

/*
========================================================================================
    PROFILES
========================================================================================
*/

profiles {
    standard {
        process.executor = 'local'
    }

    lsf {
        process.executor = 'lsf'
    }

    slurm {
        process.executor = 'slurm'
    }

    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        // Cache directory: Set via NXF_SINGULARITY_CACHEDIR env var or defaults to $HOME/.singularity/cache
        singularity.cacheDir = "${System.getenv('NXF_SINGULARITY_CACHEDIR') ?: "${System.getenv('HOME')}/.singularity/cache"}"
        singularity.pullTimeout = '240 min'
        docker.enabled = false
        podman.enabled = false
    }

    docker {
        docker.enabled = true
        docker.userEmulation = true
        singularity.enabled = false
        podman.enabled = false
    }

    test {
        // Minimal resources for testing
        params {
            max_cpus = 4
            max_memory = '8.GB'
            max_time = '1.h'
        }
    }

    debug {
        process.beforeScript = 'echo "Hostname: $(hostname)"'
        cleanup = false
    }
}

/*
========================================================================================
    EXECUTOR SETTINGS
========================================================================================
*/

executor {
    $local {
        cpus = params.max_cpus
        memory = params.max_memory
    }

    $lsf {
        queueSize = 50
        pollInterval = '30 sec'
        submitRateLimit = '10 sec'
    }

    $slurm {
        queueSize = 50
        pollInterval = '30 sec'
    }
}

/*
========================================================================================
    PROCESS DEFAULTS
========================================================================================
*/

process {
    // Default publish directory
    publishDir = [
        path: { "${params.outdir}/${task.process.tokenize(':')[-1].toLowerCase()}" },
        mode: 'copy',
        saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
    ]

    // Error handling
    errorStrategy = { task.exitStatus in [143,137,104,134,139,140] ? 'retry' : 'finish' }
    maxRetries = 2
    maxErrors = '-1'

    // Resource scaling on retry
    cpus = { check_max(1 * task.attempt, 'cpus') }
    memory = { check_max(6.GB * task.attempt, 'memory') }
    time = { check_max(4.h * task.attempt, 'time') }
}

/*
========================================================================================
    REPORTING
========================================================================================
*/

// Execution reports
def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')

timeline {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}

report {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}

trace {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

dag {
    enabled = true
    file = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

/*
========================================================================================
    MANIFEST
========================================================================================
*/

manifest {
    name            = 'fiberseq-pipeline'
    description     = 'Nextflow pipeline for processing PacBio HiFi fiber-seq data'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.0'
    version         = '1.0.0'
}

/*
========================================================================================
    FUNCTIONS
========================================================================================
*/

// Check max resources
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "WARNING: Max memory '${params.max_memory}' is not valid, using default value"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "WARNING: Max time '${params.max_time}' is not valid, using default value"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min(obj, params.max_cpus as int)
        } catch (all) {
            println "WARNING: Max cpus '${params.max_cpus}' is not valid, using default value"
            return obj
        }
    }
}
